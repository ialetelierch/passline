# WindyCity Cabs ‚Äî Senior Data Engineer Challenge

Pipeline end-to-end de datos de taxis de Chicago: ingesta incremental desde API p√∫blica ‚Üí raw ‚Üí staging ‚Üí modelo anal√≠tico en MySQL ‚Üí dashboards p√∫blicos en Looker Studio.

---

## √çndice

1. [Arquitectura del pipeline](#arquitectura-del-pipeline)
2. [Requisitos previos](#requisitos-previos)
3. [C√≥mo ejecutar el proyecto (end-to-end)](#c√≥mo-ejecutar-el-proyecto-end-to-end)
4. [Estructura del repositorio](#estructura-del-repositorio)
5. [Decisiones y trade-offs](#decisiones-y-trade-offs)
6. [Modelo anal√≠tico](#modelo-anal√≠tico)
7. [M√©tricas de negocio](#m√©tricas-de-negocio)
8. [Dashboards](#dashboards)
9. [Calidad de datos](#calidad-de-datos)
10. [Bonus implementados](#bonus-implementados)
11. [Backlog](#backlog)
12. [Uso de IA](#uso-de-ia)

---

## Arquitectura del pipeline

```mermaid
flowchart LR
    A[Chicago Data Portal\nAPI Socrata] -->|paginaci√≥n 50k| B[Raw Layer\ndata/raw/*.json]
    B -->|limpieza + casteo| C[Staging Layer\ndata/staging/*.parquet]
    C -->|INSERT IGNORE| D[(MySQL\nwindycity)]
    D --> E[fact_trips]
    D --> F[daily_kpis]
    D --> G[hourly_kpis]
    D --> H[zone_kpis]
    D --> I[zone_coords]
    D --> J[payment_kpis]
    E & F & G & H & I & J -->|export CSV| K[Google Sheets]
    K --> L[Looker Studio\n4 dashboards p√∫blicos]
```

---

## Requisitos previos

- Python 3.10+
- Docker Desktop
- Git

---

## C√≥mo ejecutar el proyecto (end-to-end)

### 1. Clonar el repositorio

```bash
git clone https://github.com/ialetelierch/passline.git
cd passline
```

### 2. Instalar dependencias Python

```bash
pip install -r requirements.txt
```

### 3. Configurar variables de entorno

```bash
cp .env.example .env
```

El `.env.example` ya incluye los valores listos para usar ‚Äî no es necesario editar nada. Si quer√©s cambiar las credenciales de MySQL, asegurate de que coincidan con las del paso siguiente.

> **Nota Windows:** el host `127.0.0.1` (en vez de `localhost`) es necesario para forzar conexi√≥n TCP/IP con el MySQL Connector. El puerto `3307` evita conflicto si ya ten√©s MySQL instalado localmente (que ocupa el `3306`).

### 4. Levantar MySQL con Docker

```bash
docker run -d --name windycity-mysql \
  -e MYSQL_ROOT_PASSWORD=windycity123 \
  -e MYSQL_DATABASE=windycity \
  -e MYSQL_USER=wc_user \
  -e MYSQL_PASSWORD=wc_pass123 \
  -p 3307:3306 \
  mysql:8.0
```

Las credenciales del comando coinciden con las del `.env.example`. Verificar que el contenedor est√° corriendo:

```bash
docker ps | grep windycity-mysql
```

### 5. Ejecutar el pipeline completo

**Opci√≥n r√°pida (recomendada):**

```bash
make run
```

Ejecuta todos los pasos del pipeline en orden: schema ‚Üí ingesta ‚Üí staging ‚Üí carga ‚Üí calidad ‚Üí exportaci√≥n. Tiempo estimado: ~15 minutos (la ingesta de ~966k registros tarda ~8 minutos).

**Paso a paso (referencia):**

```bash
python db/schema.py          # Crea las tablas en MySQL
python ingestion/ingest.py   # Descarga raw desde la API (~8 min, ~20 requests)
python ingestion/staging.py  # Transforma raw ‚Üí Parquet tipado
python db/load.py            # Carga staging ‚Üí MySQL
python quality/checks.py     # Ejecuta 7 checks ‚Äî genera quality/report.json
python exports/export.py     # Exporta tablas KPI a CSV en exports/
```

Cada paso tambi√©n tiene su propio target en el Makefile: `make schema`, `make ingest`, `make staging`, `make load`, `make quality`, `make export`.

---

## Estructura del repositorio

```
passline/
‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py          # Descarga API ‚Üí raw (JSON paginado)
‚îÇ   ‚îú‚îÄ‚îÄ staging.py         # Transforma raw ‚Üí staging (Parquet tipado)
‚îÇ   ‚îî‚îÄ‚îÄ watermark.json     # Estado incremental (generado autom√°ticamente)
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ schema.py          # Crea las tablas en MySQL
‚îÇ   ‚îî‚îÄ‚îÄ load.py            # Carga staging ‚Üí MySQL
‚îú‚îÄ‚îÄ quality/
‚îÇ   ‚îú‚îÄ‚îÄ checks.py          # Data quality checks autom√°ticos
‚îÇ   ‚îî‚îÄ‚îÄ report.json        # Reporte generado (generado autom√°ticamente)
‚îú‚îÄ‚îÄ exports/
‚îÇ   ‚îú‚îÄ‚îÄ export.py          # Exporta tablas agregadas a CSV
‚îÇ   ‚îú‚îÄ‚îÄ daily_kpis.csv
‚îÇ   ‚îú‚îÄ‚îÄ hourly_kpis.csv
‚îÇ   ‚îú‚îÄ‚îÄ zone_kpis.csv
‚îÇ   ‚îú‚îÄ‚îÄ zone_coords.csv
‚îÇ   ‚îî‚îÄ‚îÄ payment_kpis.csv
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/               # JSON paginados desde la API (gitignored)
‚îÇ   ‚îî‚îÄ‚îÄ staging/           # Parquet limpio y tipado (gitignored)
‚îú‚îÄ‚îÄ Makefile               # Orquestaci√≥n del pipeline completo
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## Decisiones y trade-offs

### Fuente de datos

- **Dataset:** Chicago Taxi Trips 2024 ‚Äî ID `ajtu-isnz`, Socrata API
- **Ventana seleccionada:** `2025-12-03` ‚Üí `2026-01-31` (60 d√≠as)
- **Motivo del rango:** se consult√≥ el `max(trip_start_timestamp)` directamente a la API antes de definir la ventana, en lugar de asumir que los datos llegan hasta hoy. El √∫ltimo dato disponible es `2026-02-01`, pero ese d√≠a tiene solo 28 registros (dato incompleto por lag de la fuente), por lo que se excluy√≥. La ventana de 60 d√≠as ofrece suficiente estacionalidad semanal y cubre dos per√≠odos festivos relevantes (Navidad y A√±o Nuevo).
- **Lag de la fuente:** el dataset tiene un lag de ~2 semanas entre que ocurre el viaje y que aparece en la API. Esto es propio de reportes municipales y se documenta como limitaci√≥n en los dashboards.

### Ingesta incremental

- **Estrategia de watermark:** se persiste la √∫ltima `trip_start_timestamp` procesada en `watermark.json`. En cada ejecuci√≥n incremental se consulta solo lo nuevo desde ese punto.
- **Idempotencia:** se usa `INSERT IGNORE` en MySQL sobre la clave primaria `trip_id`. Re-ejecutar el pipeline no duplica registros.
- **Paginaci√≥n:** 50,000 registros por request (l√≠mite de Socrata). La carga inicial requiri√≥ ~20 requests. Las cargas incrementales diarias son ~1 request (~16,000 registros/d√≠a).

### Campos descartados

| Campo | Motivo |
|---|---|
| `pickup_centroid_location` | Objeto GeoJSON redundante ‚Äî lat/lon ya vienen como campos separados |
| `dropoff_centroid_location` | √çdem |

Todos los dem√°s campos del dataset se preservan en raw y staging para decidir su uso en el modelo anal√≠tico.

### Tipos de datos

Todos los campos num√©ricos llegan como `string` desde la API (`"fare": "22.25"`). El proceso de staging castea a los tipos correctos:

| Campo | Tipo en staging |
|---|---|
| `trip_seconds` | INT |
| `trip_miles` | FLOAT |
| `fare`, `tips`, `tolls`, `extras`, `trip_total` | DECIMAL(10,2) |
| `pickup_community_area`, `dropoff_community_area` | INT |
| `pickup/dropoff_centroid_latitude/longitude` | FLOAT |
| `trip_start_timestamp`, `trip_end_timestamp` | DATETIME |

### Compatibilidad Windows con MySQL Connector

En Windows, `mysql-connector-python` intenta conectarse por named pipe cuando el host es `localhost`. Para forzar TCP/IP se usa `use_pure=True` y `host=127.0.0.1` en todos los scripts de base de datos. Esto es transparente para el usuario final pero importante para reproducibilidad en entornos Windows.

### Modelo anal√≠tico ‚Äî Opci√≥n 2 (MVP con tablas agregadas)

Se eligi√≥ tablas agregadas para BI por sobre el star schema completo porque:
- Reduce dr√°sticamente el tiempo de respuesta en Looker Studio
- Es suficiente para responder todas las preguntas de negocio definidas
- Simplifica la conexi√≥n con Google Sheets como capa intermedia sin necesidad de exponer MySQL p√∫blicamente

---

## Modelo anal√≠tico

### Tablas

| Tabla | Grain | Descripci√≥n |
|---|---|---|
| `fact_trips` | 1 fila = 1 viaje | Todos los viajes limpios y tipados |
| `daily_kpis` | 1 fila = 1 d√≠a | Revenue, viajes, tips, distancia agregados por d√≠a |
| `hourly_kpis` | 1 fila = d√≠a + hora | Volumen y revenue por hora del d√≠a |
| `zone_kpis` | 1 fila = zona de pickup | M√©tricas por community area de origen |
| `payment_kpis` | 1 fila = d√≠a + tipo de pago | Mix de m√©todos de pago por d√≠a |

### Campos derivados en fact_trips

| Campo | Descripci√≥n |
|---|---|
| `trip_hour` | Hora del d√≠a extra√≠da de `trip_start_timestamp` |
| `trip_weekday` | D√≠a de la semana (0=Lunes, 6=Domingo) |
| `trip_date` | Fecha sin hora |
| `revenue_per_mile` | `trip_total / trip_miles` |
| `tip_rate` | `tips / fare` (cuando fare > 0) |
| `is_outlier` | Flag: viaje > 3 horas O > 100 millas O fare negativo |

---

## M√©tricas de negocio

### Preguntas que responde este data product

1. **¬øC√≥mo evoluciona el revenue a lo largo del tiempo?** ‚Äî tendencias, estacionalidad y correlaci√≥n con volumen de viajes y taxis activos. ‚Üí *Dashboard 1*
2. **¬øEn qu√© horas y d√≠as de la semana hay m√°s demanda?** ‚Äî identificar picos operativos para optimizar turnos y despacho. ‚Üí *Dashboard 2*
3. **¬øQu√© empresas y m√©todos de pago concentran el negocio?** ‚Äî entender el mix de mercado y comportamiento de pago. ‚Üí *Dashboard 3*
4. **¬øDesde d√≥nde y hacia d√≥nde viajan los pasajeros?** ‚Äî identificar zonas de alta demanda para orientar la flota. ‚Üí *Dashboard 4*

### M√©tricas definidas

**M1 ‚Äî Total Revenue**
- **Definici√≥n:** suma del ingreso total de todos los viajes en el per√≠odo
- **C√°lculo:** `SUM(trip_total) WHERE is_outlier = 0`
- **Por qu√© importa:** KPI financiero principal; permite detectar ca√≠das, tendencias y comparar per√≠odos

**M2 ‚Äî Total Trips**
- **Definici√≥n:** cantidad de viajes realizados en el per√≠odo
- **C√°lculo:** `COUNT(trip_id) WHERE is_outlier = 0`
- **Por qu√© importa:** mide el volumen operativo; combinado con revenue indica si bajan precios o demanda

**M3 ‚Äî Ticket Promedio (avg_fare)**
- **Definici√≥n:** tarifa base promedio por viaje, sin propinas ni extras
- **C√°lculo:** `AVG(fare) WHERE is_outlier = 0`
- **Por qu√© importa:** permite comparar rentabilidad por zona y horario independientemente del volumen

**M4 ‚Äî Taxis Activos (active_taxis)**
- **Definici√≥n:** cantidad de taxis √∫nicos que operaron en el per√≠odo
- **C√°lculo:** `COUNT(DISTINCT taxi_id)`
- **Por qu√© importa:** mide la capacidad operativa real de la flota; cae en feriados y mal tiempo

**M5 ‚Äî Viajes por Hora del D√≠a**
- **Definici√≥n:** distribuci√≥n del volumen de viajes seg√∫n la hora de inicio
- **C√°lculo:** `SUM(total_trips) GROUP BY trip_hour`
- **Por qu√© importa:** identifica horas pico para planificar turnos y asignaci√≥n de unidades

**M6 ‚Äî Viajes por D√≠a de la Semana**
- **Definici√≥n:** distribuci√≥n del volumen seg√∫n el d√≠a de la semana
- **C√°lculo:** `SUM(total_trips) GROUP BY trip_weekday`
- **Por qu√© importa:** muestra patrones semanales que gu√≠an la planificaci√≥n operativa semanal

**M7 ‚Äî Mix de Tipo de Pago**
- **Definici√≥n:** distribuci√≥n porcentual de viajes y revenue por m√©todo de pago
- **C√°lculo:** `SUM(total_trips) / SUM(total_trips) GROUP BY payment_type`
- **Por qu√© importa:** Mobile y Credit Card dominan; Cash implica riesgo de cobranza y menor propina

**M8 ‚Äî Revenue por Empresa**
- **Definici√≥n:** revenue total generado por cada compa√±√≠a de taxis
- **C√°lculo:** `SUM(total_revenue) GROUP BY company`
- **Por qu√© importa:** Flash Cab concentra la mayor parte del mercado; permite comparar desempe√±o entre empresas

**M9 ‚Äî Revenue por Zona de Pickup**
- **Definici√≥n:** revenue total generado seg√∫n la community area de origen del viaje
- **C√°lculo:** `SUM(total_revenue) GROUP BY pickup_community_area`
- **Por qu√© importa:** identifica zonas de alta rentabilidad donde conviene concentrar la flota

**M10 ‚Äî Viajes por Zona de Dropoff**
- **Definici√≥n:** cantidad de viajes que terminan en cada community area
- **C√°lculo:** `SUM(total_trips) GROUP BY dropoff_community_area`
- **Por qu√© importa:** zonas con muchos dropoffs pero pocos pickups son zonas donde los taxis quedan vac√≠os

**M11 ‚Äî Total de Propinas (total_tips)**
- **Definici√≥n:** suma de propinas recibidas en el per√≠odo
- **C√°lculo:** `SUM(tips) WHERE is_outlier = 0`
- **Por qu√© importa:** complementa el revenue; pagos digitales generan consistentemente m√°s propinas que efectivo

**M12 ‚Äî Outlier Rate**
- **Definici√≥n:** porcentaje de viajes marcados como an√≥malos sobre el total
- **C√°lculo:** `COUNT(is_outlier=1) / COUNT(*) * 100`
- **Por qu√© importa:** controla la calidad del dato; un aumento repentino puede indicar problemas en la fuente
---

## Dashboards

Los 4 dashboards est√°n disponibles p√∫blicamente en Looker Studio (sin login):

| # | Nombre | Audiencia | Link |
|---|---|---|---|
| 1 | Revenue Overview | Direcci√≥n / CEO / CFO | [üîó Ver dashboard](https://lookerstudio.google.com/s/o52uUkD0Z94) |
| 2 | An√°lisis por hora y d√≠a de la semana | Ops Manager / Despachadores | [üîó Ver dashboard](https://lookerstudio.google.com/s/izNWAb1VmMQ) |
| 3 | Participaci√≥n por compa√±√≠a y tipo de pago | CFO / Analistas Financieros | [üîó Ver dashboard](https://lookerstudio.google.com/s/uRRdb7K8--s) |
| 4 | An√°lisis geogr√°fico pickup y dropoff | Ops Manager / Expansi√≥n | [üîó Ver dashboard](https://lookerstudio.google.com/s/mYYtH561gZU) |

### Dashboard #1 ‚Äî Revenue Overview
- **Prop√≥sito:** visi√≥n ejecutiva del negocio en el per√≠odo
- **Audiencia:** CEO, CFO, Direcci√≥n general
- **Visualizaciones:** scorecards (revenue, trips, taxis activos, tiempo total, propinas), series de tiempo de revenue / ticket promedio / taxis activos, barras apiladas de componentes del revenue (fare, tips, extras, tolls) en valores absolutos y porcentuales, scatter plots de correlaci√≥n entre revenue y variables operativas
- **Decisiones que habilita:** detectar ca√≠das de revenue, entender qu√© impulsa el ticket promedio, comparar composici√≥n del ingreso d√≠a a d√≠a
- **Fuente:** `daily_kpis`
- **Limitaciones:** lag de ~2 semanas en los datos; el d√≠a m√°s reciente puede estar incompleto

### Dashboard #2 ‚Äî An√°lisis por hora y d√≠a de la semana
- **Prop√≥sito:** planificaci√≥n operativa de turnos y despacho
- **Audiencia:** Ops Manager, coordinadores de turno
- **Visualizaciones:** tabla pivot con heatmap de % de viajes por hora √ó d√≠a de la semana, barras de total trips por hora del d√≠a, barras de total trips por d√≠a de la semana
- **Decisiones que habilita:** optimizar asignaci√≥n de unidades seg√∫n franja horaria y d√≠a, identificar horas valle donde sobran taxis
- **Fuente:** `hourly_kpis`
- **Limitaciones:** los timestamps de la API est√°n redondeados a 15 min, no son exactos al minuto

### Dashboard #3 ‚Äî Participaci√≥n por compa√±√≠a y tipo de pago
- **Prop√≥sito:** an√°lisis del mix de mercado y comportamiento de cobranza
- **Audiencia:** CFO, analistas financieros
- **Visualizaciones:** treemaps de trips y revenue por tipo de pago, treemap de revenue por empresa, barras 100% apiladas de mix de pago por empresa
- **Decisiones que habilita:** identificar empresas con mayor dependencia de cash (riesgo de cobranza), evaluar adopci√≥n de pagos digitales por empresa, detectar concentraci√≥n de mercado
- **Fuente:** `payment_kpis`
- **Limitaciones:** el campo `company` no est√° normalizado; algunas empresas aparecen con nombres ligeramente distintos

### Dashboard #4 ‚Äî An√°lisis geogr√°fico pickup y dropoff
- **Prop√≥sito:** identificar zonas de alta demanda para orientar la flota
- **Audiencia:** Ops Manager, equipo de expansi√≥n
- **Visualizaciones:** 4 mapas de burbujas sobre Chicago ‚Äî revenue por zona de pickup, trips por zona de pickup, revenue por zona de dropoff, trips por zona de dropoff
- **Decisiones que habilita:** concentrar flota en zonas de alta demanda, identificar zonas generadoras vs receptoras de pasajeros, detectar zonas con alto revenue pero bajo volumen (tickets altos)
- **Fuente:** `zone_kpis` + `zone_coords` (coordenadas promedio calculadas desde fact_trips)
- **Limitaciones:** las coordenadas son promedios por community area, no puntos exactos; O'Hare aparece como outlier dominante por su alto volumen
---

## Calidad de datos

Se implementaron 7 checks autom√°ticos en `quality/checks.py`. Resultados sobre 965,793 registros:

| Check | Resultado | Detalle |
|---|---|---|
| Nulos en campos clave | ‚ùå 1,113 nulos en `fare` | Dato faltante en la fuente, no error del pipeline. Excluidos de KPIs agregados |
| Valores negativos | ‚úÖ 0 negativos | Sin problemas |
| Unicidad `trip_id` | ‚úÖ 0 duplicados | 965,793 √∫nicos |
| Coherencia temporal | ‚ö†Ô∏è 1 viaje con end < start | Flagueado como `is_outlier`, manejado |
| Outliers | ‚úÖ 975 (0.101%) | 914 viajes > 3h, 77 viajes > 100 millas, 1 temporal |
| Consistencia de totales | ‚ö†Ô∏è 563,137 diferencias > $0.10 | Informativo, no bloqueante ‚Äî ver nota |
| Rango de fechas | ‚úÖ 2025-12-03 ‚Üí 2026-01-31 | Ventana correcta |

**5/7 checks pasaron. Los 2 restantes son advertencias informativas, no errores bloqueantes.**

### Nota sobre consistencia de totales

Al investigar las diferencias entre `trip_total` y `fare + tips + tolls + extras`, encontramos que la distribuci√≥n de diferencias es sistem√°tica (~$0.50 en la mayor√≠a de casos), lo que apunta al **Chicago Citywide Surcharge** de $0.50 por viaje. Sin embargo, la investigaci√≥n mostr√≥ que el surcharge no aplica uniformemente a todos los viajes ‚Äî var√≠a seg√∫n tipo de viaje, empresa y per√≠odo.

**Conclusi√≥n:** el campo `trip_total` incluye componentes adicionales (surcharges municipales, cargos especiales) que el dataset p√∫blico no desglosa en campos separados. No es un error del pipeline sino una limitaci√≥n de la fuente de datos. El check se mantiene como advertencia informativa.

---

## Bonus implementados

- ‚úÖ **Orquestaci√≥n liviana con Makefile** ‚Äî `make run` ejecuta el pipeline completo end-to-end; targets individuales disponibles por paso
- ‚¨ú Tests autom√°ticos + CI
- ‚¨ú Observabilidad (row counts, runtime, data freshness)
- ‚¨ú Data dictionary formal
- ‚¨ú Alertas por anomal√≠as

---

## Backlog

Qu√© har√≠a en una siguiente iteraci√≥n con m√°s tiempo:

| √çtem | Prioridad | Motivo |
|---|---|---|
| Tests autom√°ticos con pytest | Alta | Garantizar que la ingesta no rompe silenciosamente |
| Observabilidad: row counts + runtime por ejecuci√≥n | Alta | Detectar degradaci√≥n del pipeline en producci√≥n |
| Star schema completo con dimensiones | Media | M√°s flexible para an√°lisis ad-hoc |
| Alertas por anomal√≠as en revenue diario | Media | Notificar ca√≠das > 20% respecto al promedio m√≥vil |
| Modelo estad√≠stico de outliers (IQR/Z-score) | Media | M√°s robusto que las reglas heur√≠sticas actuales |
| Orquestaci√≥n con Prefect/Airflow | Baja | Para producci√≥n real; el Makefile es suficiente para MVP |
| Data dictionary formal | Baja | √ötil para equipos grandes, no cr√≠tico en MVP |

---

## Uso de IA

Se utiliz√≥ **Claude (Anthropic)** como asistente principal durante todo el desarrollo, tanto en la interfaz web claude.ai como en Claude Code (extensi√≥n VS Code).

### Influencia por √°rea

| √Årea | Influencia de IA |
|---|---|
| Exploraci√≥n de la API | Alta ‚Äî an√°lisis de respuestas y decisiones sobre campos |
| Dise√±o del pipeline | Alta ‚Äî estructura de capas, estrategia de watermark |
| C√≥digo Python (ingesta) | Alta ‚Äî generaci√≥n del script base |
| Schema MySQL | Alta ‚Äî definici√≥n de tablas y tipos |
| Definici√≥n de m√©tricas | Media ‚Äî propuestas revisadas y ajustadas manualmente |
| Documentaci√≥n (README) | Alta ‚Äî redacci√≥n del borrador base |
| Dashboards en Looker Studio | Baja ‚Äî dise√±o y configuraci√≥n manual |

### Prompts relevantes utilizados

**Exploraci√≥n de la API antes de escribir c√≥digo:**
```
Antes de definir la ventana de 60 d√≠as, consultar el max(trip_start_timestamp) 
directamente a la API para no asumir que los datos llegan hasta hoy ‚Äî 
la p√°gina de metadata dice que fue actualizado el 13 de febrero pero 
¬øc√≥mo sabemos que los datos est√°n actualizados hasta hoy?
```

**Generaci√≥n del script de ingesta:**
```
Crea un script Python de ingesta con las siguientes caracter√≠sticas:
- Ventana: 2025-12-03 al 2026-01-31 (excluir 2026-02-01 por dato incompleto, 
  solo 28 registros)
- Total esperado: ~965k registros
- Paginaci√≥n: 50,000 por request (~20 requests para carga inicial)
- Watermark: por trip_start_timestamp, granularidad diaria, 
  persistido en watermark.json
- Campos a descartar: pickup_centroid_location y dropoff_centroid_location 
  (GeoJSON redundante con lat/lon ya disponibles como campos separados)
- Todos los num√©ricos vienen como string desde la API ‚Üí castear en staging
- Mostrar progreso por p√°gina en pantalla
- Guardar raw como JSON paginado y staging como Parquet tipado
```

**Dise√±o del modelo anal√≠tico:**
```
Usar Opci√≥n 2 (MVP con tablas agregadas) por sobre star schema completo.
Tablas necesarias: fact_trips, daily_kpis, hourly_kpis, zone_kpis, payment_kpis.
Justificaci√≥n: m√°s r√°pido para BI, suficiente para responder las preguntas 
de negocio, y evita exponer MySQL p√∫blicamente usando Google Sheets como 
capa intermedia.
```

> **Nota importante:** todas las decisiones t√©cnicas (ventana de fechas, campos descartados, estrategia de watermark, elecci√≥n del modelo anal√≠tico) fueron razonadas y validadas antes de ser implementadas. El autor puede explicar y defender cada una de estas decisiones en detalle sin asistencia de IA.
